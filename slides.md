# üìä StyleVision - Documenta√ß√£o T√©cnica

## üéØ O que √© o Projeto?

**StyleVision** √© um consultor de moda inteligente baseado em IA que permite aos usu√°rios:

1. **Enviar uma imagem** do seu look (via webcam ou upload)
2. **Fazer uma pergunta** sobre a adequa√ß√£o da roupa para um contexto espec√≠fico
3. **Receber feedback especializado** de m√∫ltiplos consultores virtuais de moda

### üíé O Diferencial

O grande diferencial do StyleVision √© oferecer **diferentes opini√µes** sobre o mesmo look, utilizando modelos de IA distintos:

- **GPT-4o-mini (OpenAI)** - An√°lise t√©cnica e estruturada
- **Gemini 2.5 Flash (Google)** - Perspectiva alternativa e complementar

Isso permite ao usu√°rio ter uma vis√£o mais completa e equilibrada sobre suas escolhas de moda, similar a consultar diferentes estilistas profissionais.

### üé® Experi√™ncia do Usu√°rio

O sistema funciona de forma simples e intuitiva:
- Captura ou envia uma foto do look
- Grava uma pergunta por voz (ex: "Este look funciona para uma reuni√£o de neg√≥cios?")
- Recebe an√°lises escritas e em √°udio de consultores virtuais especializados
- Cada consultor fornece: veredito, sugest√µes de corre√ß√£o e dicas de styling

---

## üèóÔ∏è Arquitetura do Projeto

```
ProjetoMultimidia/
‚îú‚îÄ‚îÄ app.py                 # Backend Flask + SocketIO
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html         # Frontend (interface web)
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ captured.jpg       # Imagem capturada da c√¢mera
‚îÇ   ‚îú‚îÄ‚îÄ resposta_gpt.mp3   # √Åudio gerado pelo GPT
‚îÇ   ‚îú‚îÄ‚îÄ resposta_gemini.mp3 # √Åudio gerado pelo Gemini
‚îÇ   ‚îî‚îÄ‚îÄ temp_audio.wav     # √Åudio tempor√°rio da pergunta
‚îú‚îÄ‚îÄ frames/
‚îÇ   ‚îî‚îÄ‚îÄ captured_frame.jpg # Frame capturado
‚îú‚îÄ‚îÄ .env                   # Vari√°veis de ambiente (API keys)
‚îú‚îÄ‚îÄ .gitignore             # Arquivos ignorados pelo git
‚îú‚îÄ‚îÄ pyproject.toml         # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md              # Documenta√ß√£o do projeto
```

---

## üîÑ Fluxo de Funcionamento

### 1. Inicializa√ß√£o do Sistema

```mermaid
graph TD
    A[Usu√°rio acessa aplica√ß√£o] --> B[Flask inicia servidor]
    B --> C[Carrega modelo Whisper]
    C --> D[Configura APIs OpenAI/Gemini]
    D --> E[Interface pronta]
```

**C√≥digo de inicializa√ß√£o:**

```python
# app.py - Linha 27-30
app = Flask(__name__)
app.config['SECRET_KEY'] = 'gior-secret-key-2025'
socketio = SocketIO(app, cors_allowed_origins="*")

# Linha 90-97
self.client = OpenAI()
self.llm = ChatOpenAI(model='gpt-4o-mini', temperature=0, max_tokens=256)

# Whisper - usando modelo menor e mais r√°pido
print("Carregando modelo Whisper...")
try:
    self.whisper_model = WhisperModel("tiny", device="cpu", compute_type="int8")
    print("Modelo Whisper carregado!")
```

---

### 2. Captura de Imagem

```mermaid
graph LR
    A[Usu√°rio clica 'Capturar Look'] --> B[OpenCV captura frame]
    B --> C[Salva em frames/ e static/]
    C --> D[Exibe preview na interface]
```

**Implementa√ß√£o:**

```python
# app.py - M√©todo capturar_imagem
def capturar_imagem(self):
    if self.current_frame is not None:
        cv2.imwrite('frames/captured_frame.jpg', self.current_frame)
        self.imagem_capturada = 'frames/captured_frame.jpg'
        
        # Salvar tamb√©m na pasta static para exibi√ß√£o
        cv2.imwrite('static/captured.jpg', self.current_frame)
        return True
    return False
```

---

### 3. Grava√ß√£o e Transcri√ß√£o de √Åudio

```mermaid
graph TD
    A[Usu√°rio grava pergunta] --> B[MediaRecorder captura √°udio]
    B --> C[Envia via SocketIO]
    C --> D[Faster-Whisper transcreve]
    D --> E[Exibe transcri√ß√£o na tela]
```

**C√≥digo de transcri√ß√£o:**

```python
# app.py - M√©todo transcribe_audio
def transcribe_audio(self, audio_file_path):
    try:
        if self.whisper_model is None:
            # Fallback para SpeechRecognition
            with sr.AudioFile(audio_file_path) as source:
                audio = self.recognizer.record(source)
                return self.recognizer.recognize_google(audio, language='pt-BR')
        
        segments, _ = self.whisper_model.transcribe(
            audio=audio_file_path, 
            language='pt', 
            beam_size=5
        )
        transcricao = ""
        for segment in segments:
            transcricao += segment.text + " "
        return transcricao.strip()
```

---

### 4. An√°lise Dual Mode (GPT + Gemini)

```mermaid
graph TD
    A[Usu√°rio solicita an√°lise] --> B{DUAL_MODE?}
    B -->|True| C[Executa GPT e Gemini em paralelo]
    B -->|False| D[Executa apenas GPT]
    C --> E[Gera 2 √°udios separados]
    C --> F[Exibe 2 an√°lises]
    D --> G[Gera 1 √°udio]
    D --> H[Exibe 1 an√°lise]
```

**Implementa√ß√£o do Dual Mode:**

```python
# app.py - handle_descricao (linha 420-445)
if gior.dual_mode:
    print("DEBUG: Executando modo DUAL (OpenAI + Gemini)")
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as ex:
        fut_openai = ex.submit(gior.obter_resposta, pergunta)
        fut_gemini = ex.submit(gior.obter_analise_gemini, encoded_image, pergunta)
        
        try:
            resposta_gior = fut_openai.result(timeout=60)
        except Exception as e:
            resposta_gior = f"Erro OpenAI: {str(e)}"
            
        try:
            resposta_gemini = fut_gemini.result(timeout=60)
            if not resposta_gemini or resposta_gemini.startswith("Erro"):
                resposta_gemini = "N√£o foi poss√≠vel fazer a an√°lise do Gemini."
        except Exception as e:
            resposta_gemini = "N√£o foi poss√≠vel fazer a an√°lise do Gemini."
```

---

### 5. Gera√ß√£o de √Åudio com OpenAI TTS

```python
# app.py - M√©todo gerar_audio
def gerar_audio(self, texto):
    try:
        response = self.client.audio.speech.create(
            model="tts-1",
            voice="onyx",
            input=texto,
            speed=1.3
        )
        
        audio_path = 'static/resposta.mp3'
        response.stream_to_file(audio_path)
        return audio_path
    except Exception as e:
        print(f"Erro ao gerar √°udio: {e}")
        return None
```

---

## üìÅ Detalhamento de Arquivos

### **app.py** (Backend Principal)

**Responsabilidades:**
- Servidor Flask + SocketIO para comunica√ß√£o real-time
- Gerenciamento de c√¢mera (OpenCV)
- Integra√ß√£o com APIs (OpenAI GPT, Google Gemini)
- Transcri√ß√£o de √°udio (Faster-Whisper)
- Gera√ß√£o de √°udio (OpenAI TTS)

**Principais Classes:**

```python
class GiorWeb:
    """Classe principal que gerencia todo o sistema"""
    
    def __init__(self):
        # Inicializa modelos de IA
        # Configura c√¢mera
        # Define contexto do consultor de moda
        
    def ativar_camera(self):
        # Liga a webcam
        
    def capturar_imagem(self):
        # Captura e salva frame atual
        
    def obter_resposta(self, pergunta):
        # Obt√©m resposta do GPT-4o-mini com vis√£o
        
    def obter_analise_gemini(self, encoded_image, pergunta):
        # Obt√©m resposta do Google Gemini
        
    def gerar_audio(self, texto):
        # Converte texto em √°udio
```

**Rotas SocketIO:**

```python
@socketio.on('ativar_sistema')
def handle_ativar():
    # Liga a c√¢mera

@socketio.on('capturar_imagem')
def handle_capturar():
    # Captura foto do look

@socketio.on('processar_audio')
def handle_audio(data):
    # Transcreve √°udio da pergunta

@socketio.on('obter_descricao')
def handle_descricao():
    # Executa an√°lise (dual mode ou single)
    # Gera √°udios
    # Retorna HTML formatado
```

---

### **templates/index.html** (Frontend)

**Estrutura:**
- **Header:** T√≠tulo e subt√≠tulo da aplica√ß√£o
- **Grid Principal:**
  - **Coluna Esquerda:** V√≠deo da c√¢mera + preview da imagem capturada
  - **Coluna Direita:** Controles (bot√µes)
- **Se√ß√£o de Resultados:** Pergunta transcrita + an√°lises + bot√µes de √°udio

**Componentes JavaScript:**

```javascript
// Gerenciamento de eventos SocketIO
socket.on('descricao_completa', (data) => {
    // Exibe an√°lises GPT e Gemini
    // Configura bot√µes de √°udio separados
    if (data.audio_urls) {
        audioControls.style.display = "block";
        
        if (data.audio_urls.gpt) {
            audioGpt.src = data.audio_urls.gpt + "?t=" + Date.now();
            btnGpt.style.display = "inline-block";
        }
        
        if (data.audio_urls.gemini) {
            audioGemini.src = data.audio_urls.gemini + "?t=" + Date.now();
            btnGemini.style.display = "inline-block";
        }
    }
});

// Bot√µes de √°udio com controle manual
document.getElementById("playGptAudio").addEventListener("click", () => {
    const audioGpt = document.getElementById("audioGpt");
    if (audioGpt.src) {
        audioGpt.play();
    }
});
```

**CSS - Hierarquia de Bot√µes:**

```css
/* 1. DESTAQUES (Coloridos) */
.btn-primary {
    background: linear-gradient(135deg, #d4af37 0%, #aa8a2e 100%);
    /* Ativar Sistema */
}

.btn-danger {
    background: linear-gradient(135deg, #c62828 0%, #8e0000 100%);
    /* Desativar Sistema */
}

/* 2. NEUTROS (Cinza) */
#btnGravar, #btnParar, #btnCapturar {
    background: #222 !important;
    border: 1px solid #333 !important;
}

/* 3. BOT√ïES DE √ÅUDIO (Fundo da p√°gina) */
.audio-btn {
    background: radial-gradient(circle at center, #171717, #0d0d0d) !important;
    border: 1px solid #333 !important;
}
```

---

### **static/** (Arquivos Est√°ticos)

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `captured.jpg` | Imagem capturada da webcam |
| `resposta_gpt.mp3` | √Åudio da an√°lise do GPT |
| `resposta_gemini.mp3` | √Åudio da an√°lise do Gemini |
| `temp_audio.wav` | √Åudio tempor√°rio da pergunta do usu√°rio |

---

### **frames/** (Frames Tempor√°rios)

Armazena frames capturados da c√¢mera antes de serem processados.

---

### **.env** (Vari√°veis de Ambiente)

```env
OPENAI_API_KEY="sk-proj-..."
GEMINI_API_KEY="AIza..."
GEMINI_MODEL="gemini-2.5-flash"
DUAL_MODE=true
```

**Importante:** Este arquivo **n√£o** √© versionado no Git (est√° no `.gitignore`) por conter informa√ß√µes sens√≠veis.

---

## üîå APIs Utilizadas

### 1. **OpenAI GPT-4o-mini**

**Endpoint:** `ChatOpenAI` (via Langchain)

**Uso:** An√°lise de imagem + texto (vis√£o)

```python
self.llm = ChatOpenAI(model='gpt-4o-mini', temperature=0, max_tokens=256)

# Envio de mensagem com imagem
inputs = [HumanMessage(
    content=[
        {"type": "text", "text": f"{contexto}\n\n{pergunta}"},
        {"type": "image_url", "image_url": {
            "url": f"data:image/jpeg;base64,{encoded_image}"
        }}
    ]
)]
```

---

### 2. **Google Gemini**

**Endpoint:** `https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent`

**Uso:** An√°lise alternativa de imagem

```python
def obter_analise_gemini(self, encoded_image, pergunta):
    url = f'https://generativelanguage.googleapis.com/v1beta/{model}:generateContent?key={key}'
    
    payload = {
        "contents": [{
            "parts": [
                {"text": prompt_text},
                {"inline_data": {
                    "mime_type": "image/jpeg",
                    "data": encoded_image
                }}
            ]
        }]
    }
    
    r = requests.post(url, headers=headers, json=payload, timeout=25)
    return r.json()
```

---

### 3. **OpenAI TTS (Text-to-Speech)**

**Modelo:** `tts-1`

**Voz:** `onyx`

```python
response = self.client.audio.speech.create(
    model="tts-1",
    voice="onyx",
    input=texto,
    speed=1.3
)
response.stream_to_file(audio_path)
```

---

### 4. **Faster-Whisper**

**Modelo:** `tiny` (otimizado para CPU)

**Uso:** Transcri√ß√£o de √°udio em portugu√™s

```python
self.whisper_model = WhisperModel("tiny", device="cpu", compute_type="int8")

segments, _ = self.whisper_model.transcribe(
    audio=audio_file_path, 
    language='pt', 
    beam_size=5
)
```

---

## üé® Design da Interface

### Paleta de Cores

```css
/* Background */
background: radial-gradient(circle at center, #171717, #0d0d0d);

/* Cards */
background: #141414;
border: 1px solid #262626;

/* Bot√µes Dourados (Ativar Sistema) */
background: linear-gradient(135deg, #d4af37 0%, #aa8a2e 100%);

/* Bot√µes Vermelhos (Desativar/Parar) */
background: linear-gradient(135deg, #c62828 0%, #8e0000 100%);

/* Texto */
color: #f5f5f5; /* Principal */
color: #bcbcbc; /* Log entries */
```

### Tipografia

**Fonte:** Barlow (Google Fonts)

```html
<link href="https://fonts.googleapis.com/css2?family=Barlow:wght@300;400;500;600;700&display=swap" />
```

---

## üöÄ Como Executar

### 1. Instala√ß√£o de Depend√™ncias

```bash
pip install flask flask-socketio python-socketio speechrecognition pyaudio opencv-python pillow openai langchain langchain-openai langchain-community faster-whisper python-dotenv
```

### 2. Configurar `.env`

```env
OPENAI_API_KEY="sua-chave-aqui"
GEMINI_API_KEY="sua-chave-aqui"
GEMINI_MODEL="gemini-2.5-flash"
DUAL_MODE=true
```

### 3. Executar

```bash
python app.py
```

### 4. Acessar

```
http://127.0.0.1:5000
```

---

## üîß Tecnologias Utilizadas

| Categoria | Tecnologia |
|-----------|-----------|
| **Backend** | Flask, Flask-SocketIO |
| **Frontend** | HTML5, CSS3, JavaScript (Vanilla) |
| **Vis√£o Computacional** | OpenCV |
| **IA - Texto** | OpenAI GPT-4o-mini, Google Gemini |
| **IA - √Åudio** | Faster-Whisper, OpenAI TTS |
| **Processamento de Imagem** | Pillow |
| **HTTP Client** | Requests |
| **Concorr√™ncia** | concurrent.futures |

---

## üìä Fluxo Completo do Sistema

```mermaid
sequenceDiagram
    participant U as Usu√°rio
    participant F as Frontend
    participant B as Backend
    participant CV as OpenCV
    participant W as Whisper
    participant GPT as OpenAI GPT
    participant G as Google Gemini
    participant TTS as OpenAI TTS

    U->>F: Clica "Ativar Sistema"
    F->>B: Socket: ativar_sistema
    B->>CV: Ativa webcam
    CV-->>B: C√¢mera ativa
    B-->>F: sistema_status (ativo)
    
    U->>F: Clica "Capturar Look"
    F->>B: Socket: capturar_imagem
    B->>CV: Captura frame
    CV-->>B: Imagem capturada
    B-->>F: imagem_capturada (URL)
    
    U->>F: Grava pergunta
    F->>B: Socket: processar_audio
    B->>W: Transcreve √°udio
    W-->>B: Texto transcrito
    B-->>F: transcricao_completa
    
    U->>F: Clica "Obter Cr√≠tica"
    F->>B: Socket: obter_descricao
    
    par Dual Mode
        B->>GPT: Analisa imagem + pergunta
        GPT-->>B: An√°lise GPT
        B->>G: Analisa imagem + pergunta
        G-->>B: An√°lise Gemini
    end
    
    B->>TTS: Gera √°udio GPT
    TTS-->>B: resposta_gpt.mp3
    B->>TTS: Gera √°udio Gemini
    TTS-->>B: resposta_gemini.mp3
    
    B-->>F: descricao_completa (HTML + URLs)
    F-->>U: Exibe an√°lises + bot√µes de √°udio
    
    U->>F: Clica "Ouvir An√°lise GPT"
    F->>F: Toca resposta_gpt.mp3
```

---

## üéØ Funcionalidades Principais

### ‚úÖ Implementadas

1. **Captura de V√≠deo em Tempo Real**
   - Webcam ativa via OpenCV
   - Preview ao vivo na interface
   - Captura de frame est√°tico

2. **Grava√ß√£o e Transcri√ß√£o de Voz**
   - Grava√ß√£o via MediaRecorder (navegador)
   - Transcri√ß√£o com Faster-Whisper
   - Fallback para Google Speech Recognition

3. **An√°lise Dual Mode**
   - GPT-4o-mini (OpenAI)
   - Gemini 2.5 Flash (Google)
   - Execu√ß√£o paralela com ThreadPoolExecutor

4. **Gera√ß√£o de √Åudio**
   - TTS da OpenAI (voz "onyx")
   - √Åudios separados para cada an√°lise
   - Controle manual de reprodu√ß√£o

5. **Interface Responsiva**
   - Design dark elegante
   - Hierarquia visual clara
   - Feedback em tempo real

---

## üêõ Tratamento de Erros

### Backend

```python
# Tratamento de erro na an√°lise do Gemini
try:
    resposta_gemini = fut_gemini.result(timeout=60)
    if not resposta_gemini or resposta_gemini.startswith("Erro"):
        resposta_gemini = "N√£o foi poss√≠vel fazer a an√°lise do Gemini."
except Exception as e:
    resposta_gemini = "N√£o foi poss√≠vel fazer a an√°lise do Gemini."
    print(f"DEBUG: Erro no Gemini: {e}")
```

### Frontend

```javascript
socket.on("erro", (data) => {
    alert("Erro: " + data.mensagem);
    addLog("Erro: " + data.mensagem);
});
```

---

## üìà Melhorias Futuras

### üé≠ Tr√™s Consultores com Personalidades Distintas (OpenAI)

**Substitui√ß√£o do Dual Mode:**

O modo dual atual (GPT + Gemini) ser√° substitu√≠do por **tr√™s consultores virtuais**, todos utilizando a API da OpenAI, mas cada um com uma personalidade √∫nica:

**Motivo da mudan√ßa:** Limita√ß√µes de tokens dispon√≠veis na API do Gemini tornavam o dual mode inst√°vel. A solu√ß√£o com m√∫ltiplos consultores OpenAI oferece mais controle e consist√™ncia.

**Os Tr√™s Consultores:**

1. **üëî O Cl√°ssico** - Consultor tradicional e conservador
   - Foca em eleg√¢ncia atemporal
   - Prioriza regras formais de etiqueta
   - Tom profissional e respeitoso
   - Prompt: "Voc√™ √© um consultor de moda cl√°ssico e conservador..."

2. **üé® O Vanguardista** - Consultor moderno e ousado
   - Valoriza inova√ß√£o e criatividade
   - Encoraja experimenta√ß√£o de tend√™ncias
   - Tom inspirador e encorajador
   - Prompt: "Voc√™ √© um consultor de moda vanguardista e criativo..."

3. **üíº O Pragm√°tico** - Consultor direto e funcional
   - An√°lise objetiva e sem rodeios
   - Foca em praticidade e adequa√ß√£o
   - Tom honesto e construtivo (similar ao atual StyleVision)
   - Prompt: "Voc√™ √© um consultor de moda pragm√°tico e direto..."

**Implementa√ß√£o:**
```python
consultores = {
    "classico": {
        "modelo": "gpt-4o-mini",
        "contexto": "Voc√™ √© um consultor de moda cl√°ssico...",
        "voz_tts": "alloy"
    },
    "vanguardista": {
        "modelo": "gpt-4o-mini", 
        "contexto": "Voc√™ √© um consultor de moda vanguardista...",
        "voz_tts": "nova"
    },
    "pragmatico": {
        "modelo": "gpt-4o-mini",
        "contexto": "Voc√™ √© um consultor de moda pragm√°tico...",
        "voz_tts": "onyx"
    }
}
```

---

### üí¨ Chat Cont√≠nuo com Persist√™ncia de Contexto

**Evolu√ß√£o do modelo atual:**

Atualmente o sistema funciona em ciclos isolados (uma pergunta ‚Üí uma resposta). A melhoria proposta √© implementar um **chat cont√≠nuo** onde:

**Funcionalidades:**
- ‚úÖ Conversa fluida com m√∫ltiplas intera√ß√µes
- ‚úÖ Envio de v√°rias imagens ao longo da conversa
- ‚úÖ Hist√≥rico persistente da sess√£o
- ‚úÖ Contexto acumulado para an√°lises mais refinadas

**Exemplo de fluxo:**
```
Usu√°rio: [Foto 1] "O que acha desta camisa?"
Consultor: "Cor interessante, mas seria melhor com uma cal√ßa mais escura..."

Usu√°rio: [Foto 2] "E com esta cal√ßa?"
Consultor: "Perfeito! A combina√ß√£o ficou equilibrada. Agora s√≥ falta..."

Usu√°rio: "Que sapato voc√™ recomenda?"
Consultor: "Baseado no look que montamos, um oxford marrom..."
```

**Implementa√ß√£o t√©cnica:**
```python
class ChatSession:
    def __init__(self):
        self.historico = []
        self.imagens = []
        self.contexto_acumulado = ""
    
    def adicionar_mensagem(self, role, content, image=None):
        self.historico.append({
            "role": role,
            "content": content,
            "image": image,
            "timestamp": datetime.now()
        })
        self.atualizar_contexto()
    
    def obter_resposta_contextual(self, pergunta):
        # Envia todo o hist√≥rico para a API
        messages = self.formatar_historico_para_api()
        return self.llm.chat(messages)
```

**Armazenamento:**
- SessionStorage (tempor√°rio - durante navega√ß√£o)
- LocalStorage (persistente - entre sess√µes)
- Backend (opcional - com autentica√ß√£o de usu√°rio)

---

### ü™û Espelho Inteligente (Vis√£o de Longo Prazo)

**‚ö†Ô∏è Nota:** Esta funcionalidade n√£o ser√° implementada na disciplina da faculdade, mas representa a vis√£o de produto ideal.

**Conceito:**

Transformar o StyleVision em um **espelho inteligente** instalado em provadores, closets ou quartos, onde as pessoas podem:

1. **Ver-se em tempo real** com reconhecimento autom√°tico de pe√ßas
2. **Receber feedback instant√¢neo** sem precisar tirar fotos manualmente
3. **Experimentar virtualmente** diferentes combina√ß√µes
4. **Salvar hist√≥rico de looks** favoritos

**Componentes f√≠sicos:**
- Espelho com tela integrada (one-way mirror + display)
- C√¢mera embutida na moldura
- Microfone para comandos de voz
- Alto-falantes para feedback em √°udio
- Sensor de presen√ßa para ativa√ß√£o autom√°tica

**Funcionalidades avan√ßadas:**
- üé® Realidade aumentada para experimentar acess√≥rios virtuais
- üìä An√°lise de tend√™ncias pessoais ao longo do tempo
- üë• Modo social: compartilhar looks com amigos remotamente
- üõçÔ∏è Sugest√µes de compra baseadas no guarda-roupa existente
- üìÖ Planejamento de looks para a semana

**Casos de uso:**
- **Em casa:** Closet inteligente para escolha di√°ria de roupa
- **Lojas:** Provadores com consultoria virtual instant√¢nea
- **Hot√©is:** Quartos de luxo com assistente de styling
- **Academias:** Feedback sobre roupas de treino

**Arquitetura:**
```
Espelho Inteligente
    ‚Üì
Processamento Local (Edge Computing)
    ‚Üì
Cloud Backend (StyleVision API)
    ‚Üì
Modelos de IA (GPT + Vis√£o Computacional)
```

**Desafios t√©cnicos:**
- Hardware personalizado
- Processamento de v√≠deo em tempo real
- Baixa lat√™ncia para feedback instant√¢neo
- Interface touchscreen intuitiva
- Privacidade e armazenamento de imagens

---

## üîÆ Roadmap de Implementa√ß√£o

### ‚úÖ Fase 1: Atual (Conclu√≠da)
- Sistema web funcional
- Dual mode (GPT + Gemini)
- Captura de imagem e √°udio
- Feedback em texto e √°udio

### üöß Fase 2: Pr√≥ximos Passos (Disciplina)
1. **Tr√™s Consultores OpenAI** - Diferentes personalidades
2. **Chat Cont√≠nuo** - Conversas persistentes
3. **Melhorias de UX** - Interface mais fluida

### üéØ Fase 3: Expans√£o (P√≥s-faculdade)
1. **App Mobile** - iOS e Android
2. **Autentica√ß√£o** - Contas de usu√°rio
3. **An√°lise de Guarda-roupa** - Upload de todo o closet
4. **Recomenda√ß√µes Personalizadas** - Machine Learning

### üåü Fase 4: Vis√£o Final (Longo Prazo)
1. **Espelho Inteligente** - Hardware dedicado
2. **Realidade Aumentada** - Try-on virtual
3. **Integra√ß√£o com E-commerce** - Compras diretas
4. **IA Personalizada** - Modelo treinado por usu√°rio

---

## üìù Licen√ßa e Cr√©ditos

**Projeto:** StyleVision - Consultor de Moda com IA

**Desenvolvido por:** Equipe StyleVision

**Tecnologias:** Flask, OpenAI, Google Gemini, OpenCV, Faster-Whisper

**Licen√ßa:** MIT (uso educacional e n√£o comercial)

---

## üéì Conclus√£o

O **StyleVision** demonstra a integra√ß√£o de m√∫ltiplas tecnologias de IA para criar uma experi√™ncia interativa e √∫til. A arquitetura modular permite f√°cil manuten√ß√£o e expans√£o, enquanto o dual mode oferece an√°lises complementares para melhor feedback ao usu√°rio.

**Pontos Fortes:**
- Integra√ß√£o de vis√£o computacional + NLP
- Execu√ß√£o paralela de modelos
- Interface intuitiva
- Feedback em m√∫ltiplos formatos (texto + √°udio)

**Aprendizados:**
- Orquestra√ß√£o de APIs ass√≠ncronas
- Processamento de m√≠dia em tempo real
- Design de sistemas de IA conversacionais
- Gerenciamento de estado com SocketIO
